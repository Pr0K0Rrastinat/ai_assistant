import faiss
import json
import numpy as np
from pathlib import Path
from sentence_transformers import SentenceTransformer
from difflib import SequenceMatcher

# ðŸ” Ð¡Ð»Ð¾Ð²Ð°Ñ€ÑŒ ÑÐ¸Ð½Ð¾Ð½Ð¸Ð¼Ð¾Ð²
ROOM_SYNONYMS = {
    "Ð³Ð¾ÑÑ‚Ð¸Ð½Ð°Ñ": "Ð¶Ð¸Ð»Ð°Ñ ÐºÐ¾Ð¼Ð½Ð°Ñ‚Ð°",
    "ÑÐ¿Ð°Ð»ÑŒÐ½Ñ": "Ð¶Ð¸Ð»Ð°Ñ ÐºÐ¾Ð¼Ð½Ð°Ñ‚Ð°",
    "Ð´ÐµÑ‚ÑÐºÐ°Ñ": "Ð¶Ð¸Ð»Ð°Ñ ÐºÐ¾Ð¼Ð½Ð°Ñ‚Ð°",
    "ÐºÐ°Ð±Ð¸Ð½ÐµÑ‚": "Ð¶Ð¸Ð»Ð°Ñ ÐºÐ¾Ð¼Ð½Ð°Ñ‚Ð°",
    "Ñ…Ð¾Ð»Ð»": "Ð¿Ñ€Ð¸Ñ…Ð¾Ð¶Ð°Ñ",
    "Ð¿Ñ€Ð¸Ñ…Ð¾Ð¶Ð°Ñ": "Ð¿Ñ€Ð¸Ñ…Ð¾Ð¶Ð°Ñ",
    "ÑÐ°Ð½ÑƒÐ·ÐµÐ»": "Ñ‚ÑƒÐ°Ð»ÐµÑ‚",
    "Ñ.Ñƒ": "Ñ‚ÑƒÐ°Ð»ÐµÑ‚",
    "Ð²Ð°Ð½Ð½Ð°Ñ": "Ñ‚ÑƒÐ°Ð»ÐµÑ‚",
    "ÑƒÐ±Ð¾Ñ€Ð½Ð°Ñ": "Ñ‚ÑƒÐ°Ð»ÐµÑ‚",
    "Ñ‚ÑƒÐ°Ð»ÐµÑ‚": "Ñ‚ÑƒÐ°Ð»ÐµÑ‚",
    "ÐºÐ»Ð°Ð´Ð¾Ð²ÐºÐ°": "ÐºÐ»Ð°Ð´Ð¾Ð²Ð°Ñ",
    "Ð³Ð°Ñ€Ð´ÐµÑ€Ð¾Ð±": "ÐºÐ»Ð°Ð´Ð¾Ð²Ð°Ñ",
    "ÐºÑƒÑ…Ð½Ñ-Ð³Ð¾ÑÑ‚Ð¸Ð½Ð°Ñ": "ÐºÑƒÑ…Ð½Ñ",
    "ÐºÑƒÑ…Ð½Ñ-Ð½Ð¸ÑˆÐ°": "ÐºÑƒÑ…Ð½Ñ",
    "ÐºÑƒÑ…Ð½Ñ": "ÐºÑƒÑ…Ð½Ñ",
    "Ð»Ð¾Ð´Ð¶Ð¸Ñ": "Ð±Ð°Ð»ÐºÐ¾Ð½",
    "Ð±Ð°Ð»ÐºÐ¾Ð½": "Ð±Ð°Ð»ÐºÐ¾Ð½",
    "Ñ‚ÐµÑ€Ñ€Ð°ÑÐ°": "Ð±Ð°Ð»ÐºÐ¾Ð½"
    # ÐœÐ¾Ð¶Ð½Ð¾ Ð´Ð¾Ð¿Ð¾Ð»Ð½ÑÑ‚ÑŒ
}

def normalize_room_type(name: str) -> str:
    name = name.lower().strip()
    return ROOM_SYNONYMS.get(name, name)

def extract_text(value) -> str:
    if isinstance(value, str):
        return value.lower()
    elif isinstance(value, dict):
        return value.get("text", "").lower()
    elif isinstance(value, list):
        return " ".join(str(v).lower() for v in value if v)
    return ""

def similar(a: str, b: str) -> float:
    return SequenceMatcher(None, a, b).ratio()


class NormRAG:
    def __init__(self, base_dir: Path, source_file="norms_checklist_v2.json"):
        self.model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
        self.norms_path = base_dir / "index" / source_file
        self.index_path = base_dir / "index" / (Path(source_file).stem + ".index")

        with open(self.norms_path, "r", encoding="utf-8") as f:
            self.norms = json.load(f)

        self.index = faiss.read_index(str(self.index_path))

    def query(self, text: str, top_k=32, applies_to: str = None):
        query_vec = self.model.encode([text])
        D, I = self.index.search(np.array(query_vec), top_k * 2)
        candidates = [self.norms[i] for i in I[0]]

        if applies_to:
            applies_vec = self.model.encode([applies_to])[0]
            scored = []
            for norm in candidates:
                applies = norm.get("applies_to", [])
                if isinstance(applies, str):
                    applies = [applies]
                applies = [a for a in applies if isinstance(a, str)]
                if not applies:
                    continue

                apply_vecs = self.model.encode([a.lower() for a in applies])
                best_score = max(np.dot(vec, applies_vec) for vec in apply_vecs)
                if best_score > 0.6:  # Ð¿Ð¾Ñ€Ð¾Ð³
                    scored.append(norm)

            if scored:
                candidates = scored
        return candidates[:top_k]
