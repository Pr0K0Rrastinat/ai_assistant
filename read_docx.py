import requests
import time

def dedup_norms(norms):
    seen = set()
    deduped = []
    for norm in norms:
        text = norm.get("text", "")
        if text not in seen:
            deduped.append(norm)
            seen.add(text)
    return deduped

def split_into_batches(norms, batch_size):
    for i in range(0, len(norms), batch_size):
        yield norms[i:i + batch_size]

def generate_multi_norm_prompt(norms, fact_text):
    norms_text = "\n\n".join([f"- {n.get('text', '')}" for n in norms])
    prompt = (
        f"–í–æ–ø—Ä–æ—Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–∞:\n{fact_text.strip()}\n\n"
        f"–°–ª–µ–¥—É—é—â–∏–µ –Ω–æ—Ä–º—ã –º–æ–≥—É—Ç –æ—Ç–Ω–æ—Å–∏—Ç—å—Å—è –∫ –≤–æ–ø—Ä–æ—Å—É:\n{norms_text}\n\n"
        "–ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö –Ω–æ—Ä–º, –¥–∞–π –∫—Ä–∞—Ç–∫–∏–π, –ø–æ–ª–µ–∑–Ω—ã–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
    )
    return prompt

import re

def clean_llm_output(text):
    # –£–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π –≤ —Ç–µ–≥–µ <think>...</think>
    return re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL).strip()


def check_multi_norm_with_llama(norms, fact_text, model_name="qwen3"):
    if not norms:
        return "‚ùó –ù–æ—Ä–º–∞—Ç–∏–≤—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞."

    norms = dedup_norms(norms)
    all_responses = []
    batches = list(split_into_batches(norms, 8))

    total = len(batches)
    print(f"üì¶ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(norms)} –Ω–æ—Ä–º. –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ {total} –±–∞—Ç—á–µ–π –ø–æ 8 –Ω–æ—Ä–º:\n")

    start_time = time.time()

    for i, batch in enumerate(batches, start=1):
        print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {i}/{total}... ", end="", flush=True)
        prompt = generate_multi_norm_prompt(batch, fact_text)

        try:
            response = requests.post("http://localhost:11434/api/generate", json={
                "model": model_name,
                "prompt": prompt,
                "stream": False
            })
            response.raise_for_status()
            data = response.json()
            result = data.get("response", "‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")
            all_responses.append(result.strip())
            print("‚úÖ –ì–æ—Ç–æ–≤–æ")
        except requests.exceptions.RequestException as e:
            error_msg = f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ LLaMA (–±–∞—Ç—á {i}): {str(e)}"
            all_responses.append(error_msg)
            print("‚ùå –û—à–∏–±–∫–∞")

        time.sleep(1.5)

    end_time = time.time()
    elapsed = end_time - start_time
    print(f"\nüèÅ –í—Å–µ –±–∞—Ç—á–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∑–∞ {round(elapsed, 2)} —Å–µ–∫.\n")

    return clean_llm_output("\n\n".join(all_responses))
